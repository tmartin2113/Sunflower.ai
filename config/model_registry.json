{
  "version": "1.0",
  "last_updated": "2025-01-01",
  
  "base_models": {
    "llama3.2:1b-q4_0": {
      "name": "Llama 3.2 1B (Quantized)",
      "size_mb": 700,
      "min_ram_gb": 2,
      "recommended_ram_gb": 4,
      "quality_score": 6,
      "speed_score": 10,
      "description": "Smallest model, works on all systems",
      "download_url": "ollama pull llama3.2:1b-q4_0",
      "parameters": {
        "context_size": 2048,
        "batch_size": 8,
        "threads": "auto"
      }
    },
    
    "llama3.2:1b": {
      "name": "Llama 3.2 1B",
      "size_mb": 1400,
      "min_ram_gb": 4,
      "recommended_ram_gb": 6,
      "quality_score": 7,
      "speed_score": 9,
      "description": "Small model with good quality",
      "download_url": "ollama pull llama3.2:1b",
      "parameters": {
        "context_size": 4096,
        "batch_size": 16,
        "threads": "auto"
      }
    },
    
    "llama3.2:3b": {
      "name": "Llama 3.2 3B",
      "size_mb": 2100,
      "min_ram_gb": 6,
      "recommended_ram_gb": 8,
      "quality_score": 8,
      "speed_score": 7,
      "description": "Balanced model for most users",
      "download_url": "ollama pull llama3.2:3b",
      "parameters": {
        "context_size": 4096,
        "batch_size": 16,
        "threads": "auto"
      }
    },
    
    "llama3.1:8b": {
      "name": "Llama 3.1 8B",
      "size_mb": 4700,
      "min_ram_gb": 12,
      "recommended_ram_gb": 16,
      "quality_score": 9,
      "speed_score": 5,
      "description": "High quality for powerful systems",
      "download_url": "ollama pull llama3.1:8b",
      "parameters": {
        "context_size": 8192,
        "batch_size": 32,
        "threads": "auto"
      }
    },
    
    "llama3.1:70b": {
      "name": "Llama 3.1 70B",
      "size_mb": 42000,
      "min_ram_gb": 48,
      "recommended_ram_gb": 64,
      "quality_score": 10,
      "speed_score": 2,
      "description": "Best quality for high-end systems",
      "download_url": "ollama pull llama3.1:70b",
      "parameters": {
        "context_size": 8192,
        "batch_size": 32,
        "threads": "auto"
      }
    }
  },
  
  "sunflower_models": {
    "sunflower-kids": {
      "name": "Sunflower AI Kids",
      "version": "2.0",
      "base_model": "llama3.2:3b",
      "modelfile": "Sunflower_AI_Kids.modelfile",
      "description": "Primary AI for children ages 2-18",
      "features": [
        "Age-adaptive responses",
        "Built-in safety filters",
        "STEM education focus",
        "Progress tracking",
        "Parent alerts"
      ],
      "safety_level": "maximum",
      "target_audience": "children",
      "parameters": {
        "temperature": 0.8,
        "top_p": 0.9,
        "repeat_penalty": 1.1
      }
    },
    
    "sunflower-educator": {
      "name": "Sunflower AI Educator",
      "version": "2.0",
      "base_model": "llama3.2:3b",
      "modelfile": "Sunflower_AI_Educator.modelfile",
      "description": "Professional assistant for parents and teachers",
      "features": [
        "Lesson planning",
        "Curriculum development",
        "Progress analysis",
        "Resource creation",
        "Standards alignment"
      ],
      "safety_level": "standard",
      "target_audience": "adults",
      "parameters": {
        "temperature": 0.7,
        "top_p": 0.9,
        "repeat_penalty": 1.1
      }
    }
  },
  
  "hardware_recommendations": {
    "minimal": {
      "ram_gb": 4,
      "cpu_cores": 2,
      "gpu": false,
      "recommended_model": "llama3.2:1b-q4_0",
      "expected_performance": {
        "response_time_seconds": "5-10",
        "quality": "basic",
        "concurrent_users": 1
      }
    },
    
    "standard": {
      "ram_gb": 8,
      "cpu_cores": 4,
      "gpu": false,
      "recommended_model": "llama3.2:3b",
      "expected_performance": {
        "response_time_seconds": "2-5",
        "quality": "good",
        "concurrent_users": 1
      }
    },
    
    "recommended": {
      "ram_gb": 16,
      "cpu_cores": 6,
      "gpu": true,
      "recommended_model": "llama3.1:8b",
      "expected_performance": {
        "response_time_seconds": "1-3",
        "quality": "excellent",
        "concurrent_users": 2
      }
    },
    
    "premium": {
      "ram_gb": 32,
      "cpu_cores": 8,
      "gpu": true,
      "recommended_model": "llama3.1:8b",
      "expected_performance": {
        "response_time_seconds": "<2",
        "quality": "excellent",
        "concurrent_users": 3
      }
    }
  },
  
  "age_model_mapping": {
    "2-5": {
      "preferred_models": ["llama3.2:1b-q4_0", "llama3.2:1b"],
      "max_response_length": 50,
      "complexity": "very_simple"
    },
    
    "6-8": {
      "preferred_models": ["llama3.2:1b", "llama3.2:3b"],
      "max_response_length": 75,
      "complexity": "simple"
    },
    
    "9-12": {
      "preferred_models": ["llama3.2:3b", "llama3.1:8b"],
      "max_response_length": 125,
      "complexity": "moderate"
    },
    
    "13-16": {
      "preferred_models": ["llama3.2:3b", "llama3.1:8b"],
      "max_response_length": 200,
      "complexity": "advanced"
    },
    
    "17-18": {
      "preferred_models": ["llama3.1:8b", "llama3.1:70b"],
      "max_response_length": 300,
      "complexity": "college_prep"
    }
  },
  
  "model_selection_rules": {
    "priority_order": [
      "user_preference",
      "hardware_capability",
      "age_appropriateness",
      "quality_requirement"
    ],
    
    "fallback_strategy": "downgrade_gracefully",
    
    "performance_thresholds": {
      "max_response_time": 10,
      "min_quality_score": 6,
      "memory_safety_margin": 0.2
    }
  }
}
